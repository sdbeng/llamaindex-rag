# llamaindex-rag

## WHat is Context Augmentation

LLMs offer a natural language interface between humans and data. LLMs come pre-trained on huge amounts of publicly available data, but they are not trained on your data. Your data may be private or specific to the problem you're trying to solve. It's behind APIs, in SQL databases, or trapped in PDFs and slide decks.

Context augmentation makes your data available to the LLM to solve the problem at hand. LlamaIndex provides the tools to build any of context-augmentation use case, from prototype to production. LlamaIndex tools allow you to ingest, parse, index and process your data and quickly implement complex query workflows combining data access with LLM prompting.i.e RAG

## Agents

Agents are LLM-powered knowledge assistants that use tools to perform tasks like research, data extraction, and more. Agents range from simple question-answering to being able to sense, decide and take actions in order to complete tasks.

LlamaIndex provides a framework for building agents including the ability to use RAG pipelines as one of many tools to complete a task.

## Workflows

Workflows are multi-step processes that combine one or more agents, data connectors, and other tools to complete a task. They are event-driven software that allows you to combine RAG data sources and multiple agents to create a complex application that can perform a wide variety of tasks with reflection, error-correction, and other hallmarks of advanced LLM applications. You can then deploy these agentic workflows as production microservices.

## Use cases

Use cases#
Some popular use cases for LlamaIndex and context augmentation in general include:

- Question-Answering (Retrieval-Augmented Generation aka RAG)
- Chatbots
- Document Understanding and Data Extraction
- Autonomous Agents that can perform research and take actions
- Multi-modal applications that combine text, images, and other data types
- Fine-tuning models on data to improve performance
